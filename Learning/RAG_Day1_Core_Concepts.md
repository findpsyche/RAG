# 🟦 Day 1: RAG 是什么 & 为什么 ToB 离不开它

## 重要认知：RAG 是 ToB 的"保命武器"

在奇绩创坛 / ToB 场景中：
- **RAG ≈ FDE 的 AK47**
- 不是锦上添花，是保命武器
- 99% 的被投公司有文档、有知识、但没有"可用的AI接口"

---

## 🎯 RAG 的最小结构

```
文档 → Chunk → Embedding → Vector DB
                   ↓
        用户问题 → 检索 → LLM → 回答
```

### 工作流程解析：
1. **文档处理**：获取各种格式的文档（PDF、Markdown、Excel等）
2. **分块(Chunk)**：将文档切割成合适大小的文本块
3. **嵌入(Embedding)**：将文本转换为向量表示（数值向量）
4. **存储**：将向量存入数据库（Vector DB）
5. **检索**：用户问题转化为向量，从库中找到相关文档
6. **增强**：将检索结果和用户问题一起送给LLM
7. **生成**：LLM基于检索结果生成更准确的回答

---

## 🔥 为什么 ToB 场景必须用 RAG？

### 微调 ≠ 快速落地
- ❌ 微调模型：耗时、成本高、效果难以预测
- ✅ RAG 是最快的"看见价值"方案：1-2周能看到效果

### 现状分析
- 99% 被投公司的痛点：
  - ✓ 有大量文档和知识
  - ✓ 想要 AI 能回答关于这些文档的问题
  - ✗ 直接问 LLM 很泛、很容易幻觉
  - ✗ LLM 不知道他们的专有数据

### RAG 的价值主张
- **快速迭代**：不需要重新训练模型
- **成本低**：利用现成的大模型+开源向量库
- **立竿见影**：几小时就能看到初步效果
- **可控风险**：通过调整检索策略降低幻觉

---

## 📚 必须搞懂的 5 个关键点

### 1️⃣ Chunk Size 怎么影响效果？

**核心权衡：**
```
较小 Chunk（如 256 tokens）
  ✓ 精准度高（相关性更强）
  ✗ 碎片化风险（上下文丢失）
  ✗ 检索命中可能不足

较大 Chunk（如 1024 tokens）
  ✓ 保留完整上下文
  ✗ 噪音增加（不相关内容混入）
  ✗ Token 消耗多
```

**最佳实践：**
- 默认从 512 tokens 开始
- 根据具体文档类型调整
- 法律文书：大 chunk（保持逻辑连贯）
- 技术文档：中 chunk（清晰的段落分割）
- FAQ：小 chunk（单个问答对）

### 2️⃣ Embedding 模型不是越大越好

**常见误区：**
- ❌ "用最强的 Embedding 模型就能解决问题"

**真相：**
```
模型大小 vs 效果
  小型模型（384 dim）→ 快速、便宜、足以应对大多数场景
  中型模型（768 dim）→ 平衡方案（推荐用这个）
  大型模型（1536 dim）→ 精确但缓慢、成本高

实际效果：合适的 chunk size > 单纯用更强模型
```

**选择标准：**
- **本地部署**：用小型模型（m3e、bge-small）
- **API 调用**：用专业模型（OpenAI Embedding、Qwen）
- **成本/效果**：中型模型通常最优

### 3️⃣ Top-K 怎么影响 Hallucination？

**原理：**
```
Top-K = 从向量库中检索最相关的 K 个文档块
```

**对幻觉(Hallucination)的影响：**
```
K=1（太小）
  ✓ 快速、成本低
  ✗ 容易遗漏、幻觉高

K=5（通常最优）
  ✓ 信息完整
  ✗ 有冗余但可控

K=10+（过大）
  ✗ 引入噪音、增加幻觉
  ✗ Token 消耗大、成本高
  ✗ LLM 容易混淆
```

**经验法则：**
- 对于事实性问题：K=3-5（足以覆盖）
- 对于复杂问题：K=5-10（多角度理解）
- 对于幻觉敏感业务（法律/医疗）：K=3 + 严格过滤

### 4️⃣ RAG 能解决什么，不能解决什么？

#### ✅ RAG 适合的场景
- 📄 **基于文档的问答**：查询特定章节、条款、数据
- 📊 **多文档综合**：跨多份文件找答案
- 🔍 **需要溯源**：能指出"答案来自哪里"
- 📈 **频繁更新**：加新文档不用重新训练
- 💼 **专有知识**：企业内部 SOP、产品文档等

#### ❌ RAG 搞不定的场景
- 🧠 **推理复杂**：需要多步骤逻辑推导（用 Agent）
- 🎨 **创意生成**：写文案、设计创意（用微调）
- 🔗 **跨域综合**：需要组合多个知识源进行深度推理
- 🔢 **实时计算**：需要调用 API、执行代码（用 Tool Calling）
- 📡 **多模态**：需要理解图片、视频等（用多模态模型）

### 5️⃣ 什么时候要说"不适合 RAG"？

**FDE 的救命技能：**

判断一个问题 **不适合 RAG** 的信号：

```
❌ 问题特征               → 应该用什么
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
"我需要代码运行结果"      → Tool Calling + API
"这需要多步推理"          → Agent (ReAct/Chain-of-thought)
"需要和实时系统交互"      → 集成第三方 API（CRM、ERP）
"需要个性化/学习偏好"     → 用户行为数据 + 微调
"完全超出文档范围"        → LLM 本身的知识足够吗？
```

---

## ✅ Day 1 的「够用标准」

### 学习目标（5分钟白板讲清楚）
你应该能用白板 5 分钟给创始人讲清楚：

**核心一句话：**
> "RAG 就是让 AI 先读你的文档，再回答你的问题——这样答案准确，而且有出处。"

**需要讲清的5点：**
1. ✅ 文档 → 向量 → 数据库（什么是 Vector DB）
2. ✅ 用户问题也变向量，找最相似的文档
3. ✅ 把找到的文档 + 问题 一起给 LLM
4. ✅ LLM 就能给出有依据的回答
5. ✅ 为什么能解决"幻觉"问题

### 实际操作能力
你需要能够：
- 🎯 列出 5 个 Chunk Size 选择会影响结果的具体例子
- 🎯 解释为什么某次检索结果不好（是 Embedding 问题还是 Chunk 问题？）
- 🎯 给出调整 Top-K 的理由（为什么这个问题要用 K=5 而不是 K=3）

---

## 🎬 实战演练：Day 1 自测

### 问题 1：
**你的公司是一个律师事务所，有 500 份合同。**
- 应该用什么 Chunk Size？为什么？
- **答案：** 大 chunk（1000+ tokens），因为法律逻辑需要保持连贯性

### 问题 2：
**用户问："公司 2024 年的营收是多少？"**
- 这是 RAG 的工作吗？为什么/为什么不？
- **答案：** 是的。这是典型的基于文档的事实查询

### 问题 3：
**"请帮我做一个营销策略，结合公司资产、竞争对手分析和市场趋势"**
- 用 RAG 够吗？为什么？
- **答案：** 不够。需要 Agent（多步推理）+ 外部 API + RAG 的组合

---

## 📌 记住这个核心区别

| 概念 | 定义 | 用在什么时候 |
|------|------|-----------|
| **检索** | 从库里找相关文档 | RAG 的核心 |
| **Embedding** | 文本 → 向量 | 衡量两段文本的相似度 |
| **向量数据库** | 存 embedding、快速检索 | Pinecone、Weaviate、Milvus |
| **Chunk** | 文档分块单位 | 平衡精准度和完整性 |
| **幻觉** | LLM 编造信息 | RAG 最大敌人 |

---

## 🔗 Day 1 总结清单

- [ ] 理解 RAG 的 6 步工作流
- [ ] 知道 5 个关键调参
- [ ] 能用 1 句话解释 RAG 的价值
- [ ] 知道什么问题不适合用 RAG
- [ ] 能判断具体场景是否适合 RAG

**下一步：** Day 2 学习如何根据公司类型定制 RAG 方案
