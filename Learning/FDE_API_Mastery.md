# ğŸ¯ FDE API è°ƒç”¨ç²¾é€šæŒ‡å— (ç¬¬ 2 å¤©)

**ç›®æ ‡**: æŒæ¡ System Prompt è°ƒè¯•ï¼Œå¤„ç†é•¿æ–‡æœ¬æˆªæ–­ä¸ JSON Mode è¾“å‡ºã€‚

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šSystem Prompt è°ƒè¯•è‰ºæœ¯ (2h)

### ä¸ºä»€ä¹ˆ System Prompt è¿™ä¹ˆé‡è¦ï¼Ÿ

åŒä¸€ä¸ª APIï¼Œä¸åŒçš„ System Promptï¼Œè¾“å‡ºå®Œå…¨ä¸åŒï¼š

```python
question = "What should a startup do to grow?"

# âœ… æ¡ˆä¾‹ 1: å•†ä¸šé¡¾é—®é£æ ¼
response1 = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {
            "role": "system",
            "content": "You are a seasoned venture capitalist with 20 years of experience. Provide strategic, data-driven advice for startup growth. Be concise."
        },
        {"role": "user", "content": question}
    ]
)
# è¾“å‡º: Focus on product-market fit metrics. If CAC > LTV, revisit positioning...

# âœ… æ¡ˆä¾‹ 2: åŠ±å¿—æ•™ç»ƒé£æ ¼
response2 = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {
            "role": "system",
            "content": "You are a motivational startup coach. Give encouraging, actionable advice focused on team morale and persistence."
        },
        {"role": "user", "content": question}
    ]
)
# è¾“å‡º: Believe in your vision! Growth comes from consistency and..

# âœ… æ¡ˆä¾‹ 3: å¾‹å¸ˆ/é£é™©è§„é¿é£æ ¼
response3 = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {
            "role": "system",
            "content": "You are a cautious legal advisor. Point out all potential risks and compliance issues. Be thorough."
        },
        {"role": "user", "content": question}
    ]
)
# è¾“å‡º: Ensure regulatory compliance first. Verify IP rights, employment..
```

**å…³é”®æ´å¯Ÿ**: ä¸åŒçš„ System Prompt æ¿€æ´»äº† LLM ä¸åŒçš„"çŸ¥è¯†"ã€‚é€‰å¯¹äº†ï¼Œè´¨é‡æå‡ 5 å€ã€‚

---

## System Prompt æœ€ä½³å®è·µ

### åŸåˆ™ 1: è§’è‰²å®šä½è¦å…·ä½“

```python
# âŒ å¤ªå®½æ³›
"You are a helpful assistant."

# âœ… å…·ä½“æœ‰åŠ›
"You are an expert product manager at a Series B SaaS company. You have shipped 5 products and understand the complete product-engineering-design workflow."
```

### åŸåˆ™ 2: æŒ‡å®šè¾“å‡ºæ ¼å¼

```python
# âŒ æ ¼å¼æ¨¡ç³Š
"Summarize this document."

# âœ… æ ¼å¼æ¸…æ™°
"""Summarize this document in the following format:
- Key Points (3-5 bullet points)
- Risks (2-3)
- Recommended Actions (2-3)
Return as JSON."""
```

### åŸåˆ™ 3: æŒ‡å®šè¯­æ°”å’Œé£æ ¼

```python
# âŒ é£æ ¼ä¸æ¸…æ¥š
"Write an article about AI."

# âœ… é£æ ¼æ˜ç¡®
"""Write a technical blog post for experienced ML engineers. 
- Target audience: 10+ years in ML
- Tone: Insightful, data-driven, sometimes humorous
- Length: 1500 words
- Structure: Intro -> Problem -> Solution -> Benchmark -> Lessons"""
```

### åŸåˆ™ 4: ç»™å‡ºåé¢ä¾‹å­

```python
system_prompt = """You are a data analyst summarizing research papers.

CORRECT approach:
"The paper demonstrates a 15% improvement in latency through..."

INCORRECT approach:
"The paper is really interesting and shows that..."

Always be specific with numbers and mechanisms."""
```

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šå¤„ç†è¶…é•¿ä¸Šä¸‹æ–‡ (2h)

### é—®é¢˜ï¼šToken é™åˆ¶

```
GPT-3.5-turbo:   4K tokens (çº¦ 3000 å­—)
GPT-4:           8K / 32K / 128K tokens
Claude 3 Opus:   200K tokens
Llama 2:         4K tokens
```

### åœºæ™¯ 1: æ–‡æ¡£æ€»ç»“

```python
def summarize_long_document(doc_path, chunk_size=2000):
    """
    åˆ†å—æ€»ç»“è¶…é•¿æ–‡æ¡£
    """
    with open(doc_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æŒ‰å­—ç¬¦æ•°åˆ†å—ï¼ˆä¸æ˜¯å®Œç¾çš„ï¼Œä½†å¿«é€Ÿï¼‰
    chunks = [content[i:i+chunk_size] for i in range(0, len(content), chunk_size)]
    
    chunk_summaries = []
    for i, chunk in enumerate(chunks):
        print(f"å¤„ç†å— {i+1}/{len(chunks)}")
        summary = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Summarize the following text in 3-5 bullet points."},
                {"role": "user", "content": chunk}
            ]
        ).choices[0].message.content
        chunk_summaries.append(summary)
    
    # æœ€ç»ˆæ±‡æ€»
    final_summary = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "Merge these summaries into a comprehensive overview."},
            {"role": "user", "content": "\n\n".join(chunk_summaries)}
        ]
    ).choices[0].message.content
    
    return final_summary
```

### åœºæ™¯ 2: åˆåŒå®¡æŸ¥ï¼ˆåªçœ‹å…³é”®éƒ¨åˆ†ï¼‰

```python
def extract_key_sections(contract_text):
    """
    ä¸æ˜¯è¯»æ•´ä¸ªåˆåŒï¼Œè€Œæ˜¯è®© AI å…ˆè¯†åˆ«å…³é”®éƒ¨åˆ†
    """
    # ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«å…³é”®ç« èŠ‚
    response1 = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": "Identify the most important sections in this contract (sections about payment, termination, liability, etc.). Return as a list of line numbers or section headers."
            },
            {"role": "user", "content": contract_text[:3000]}  # åªçœ‹å‰ 3000 å­—è¯†åˆ«ç»“æ„
        ]
    ).choices[0].message.content
    
    print(f"å…³é”®éƒ¨åˆ†:\n{response1}")
    
    # ç¬¬äºŒæ­¥ï¼šåªæ·±å…¥åˆ†æå…³é”®éƒ¨åˆ†
    response2 = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": "Analyze these contract sections for risks. Focus on: payment terms, termination clauses, liability caps, and exclusions."
            },
            {"role": "user", "content": response1 + "\n\nNow analyze the full contract..."}
        ]
    ).choices[0].message.content
    
    return response2
```

### åœºæ™¯ 3: æ—¥å¿—åˆ†æï¼ˆæ™ºèƒ½é‡‡æ ·ï¼‰

```python
import json
from datetime import datetime, timedelta

def analyze_logs_intelligently(log_file):
    """
    å¤„ç†ç™¾ä¸‡çº§æ—¥å¿—ï¼Œä½†åªåˆ†ææœ€ç›¸å…³çš„éƒ¨åˆ†
    """
    with open(log_file) as f:
        lines = f.readlines()
    
    # ç­–ç•¥ï¼šé‡‡æ ·æœ€å 500 è¡Œ + é”™è¯¯æ—¥å¿—
    critical_lines = []
    
    # åŠ å…¥æœ€å 500 è¡Œ
    critical_lines.extend(lines[-500:])
    
    # åŠ å…¥æ‰€æœ‰ ERROR å’Œ CRITICAL æ—¥å¿—
    for line in lines:
        if 'ERROR' in line or 'CRITICAL' in line:
            critical_lines.append(line)
    
    # å»é‡å¹¶æ’åº
    critical_lines = list(set(critical_lines))
    critical_text = "".join(critical_lines[:1000])  # æœ€å¤š 1000 è¡Œ
    
    analysis = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "system",
                "content": "Analyze these application logs. Identify: 1) Root cause of issues 2) Severity 3) Recommended actions"
            },
            {"role": "user", "content": critical_text}
        ]
    ).choices[0].message.content
    
    return analysis
```

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šJSON Mode ä¸ç»“æ„åŒ–è¾“å‡º (1h)

### ä¸ºä»€ä¹ˆéœ€è¦ JSON Modeï¼Ÿ

```python
# âŒ é—®é¢˜ï¼šè®© AI è¿”å› JSONï¼Œä½†ç»“æœä¸ç¨³å®š
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {
            "role": "user",
            "content": 'Extract name, age, email from "John Smith, 30, john@example.com". Return as JSON.'
        }
    ]
)

# æœ‰æ—¶è¿”å›: {"name": "John Smith", "age": 30, "email": "john@example.com"}
# æœ‰æ—¶è¿”å›: "Here is the JSON: {\"name\": \"John Smith\", ...}"
# æœ‰æ—¶è¿”å›: "John Smith is 30 years old. Email: john@example.com"

# ç»“æœæ··ä¹±ï¼

# âœ… è§£å†³ï¼šç”¨ JSON Modeï¼ˆGPT-4 å’ŒæŸäº› GPT-3.5 ç‰ˆæœ¬æ”¯æŒï¼‰
response = client.chat.completions.create(
    model="gpt-4-turbo",
    messages=[
        {
            "role": "system",
            "content": "You always respond with valid JSON."
        },
        {
            "role": "user",
            "content": 'Extract name, age, email from "John Smith, 30, john@example.com"'
        }
    ],
    response_format={"type": "json_object"}
)

# ç°åœ¨ä¸€å®šè¿”å› valid JSON
result = json.loads(response.choices[0].message.content)
print(result["name"])  # å®‰å…¨ï¼ä¸ä¼šæŠ¥é”™
```

### åœºæ™¯ 1: æ•°æ®æå–

```python
import json
from typing import Any

def extract_data_from_text(text: str) -> dict:
    """
    ä»ä»»æ„æ–‡æœ¬æå–ç»“æ„åŒ–æ•°æ®
    """
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[
            {
                "role": "system",
                "content": """You are a data extraction expert. 
Extract the following fields and return valid JSON:
- person_name
- company
- job_title
- contact_email
- key_achievements (list of 3 items)

If a field is not found, use null."""
            },
            {
                "role": "user",
                "content": f"Extract data from: {text}"
            }
        ],
        response_format={"type": "json_object"}
    )
    
    return json.loads(response.choices[0].message.content)

# ä½¿ç”¨
text = "Meet Jane Doe, VP of Product at Acme Corp. She led 3 successful launches. Contact: jane@acme.com"
data = extract_data_from_text(text)
print(data["person_name"])  # Jane Doe
```

### åœºæ™¯ 2: åˆ†ç±»ä»»åŠ¡

```python
def classify_support_ticket(ticket_text: str) -> dict:
    """
    å¯¹å®¢æœå·¥å•è¿›è¡Œåˆ†ç±»å’Œä¼˜å…ˆçº§è¯„å®š
    """
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[
            {
                "role": "system",
                "content": """Classify the support ticket. Return JSON:
{
    "category": "billing|technical|feature_request|other",
    "priority": "low|medium|high|critical",
    "sentiment": "positive|neutral|negative",
    "suggested_response_type": "automated|escalate|follow_up",
    "summary": "Brief summary"
}"""
            },
            {
                "role": "user",
                "content": ticket_text
            }
        ],
        response_format={"type": "json_object"}
    )
    
    return json.loads(response.choices[0].message.content)

# ä½¿ç”¨
ticket = "My invoice shows $500 but I only used API 10 times. This is a billing error!"
result = classify_support_ticket(ticket)
print(f"ä¼˜å…ˆçº§: {result['priority']}")  # high
print(f"åˆ†ç±»: {result['category']}")     # billing
```

### åœºæ™¯ 3: å¤šæ­¥éª¤å·¥ä½œæµ

```python
def process_job_application(resume_text: str, job_description: str) -> dict:
    """
    è¯„ä¼°æ±‚èŒè€…å’ŒèŒä½çš„åŒ¹é…åº¦ï¼ˆå¤šæ­¥éª¤ï¼‰
    """
    
    # æ­¥éª¤ 1: æå–æ±‚èŒè€…ä¿¡æ¯
    step1_response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[
            {
                "role": "system",
                "content": """Extract from resume:
{
    "name": "",
    "experience_years": 0,
    "key_skills": [],
    "past_companies": [],
    "education": ""
}"""
            },
            {"role": "user", "content": resume_text}
        ],
        response_format={"type": "json_object"}
    ).choices[0].message.content
    
    candidate = json.loads(step1_response)
    
    # æ­¥éª¤ 2: æå–èŒä½è¦æ±‚
    step2_response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[
            {
                "role": "system",
                "content": """Extract from job description:
{
    "position_title": "",
    "required_experience_years": 0,
    "required_skills": [],
    "preferred_skills": [],
    "education_requirement": ""
}"""
            },
            {"role": "user", "content": job_description}
        ],
        response_format={"type": "json_object"}
    ).choices[0].message.content
    
    job = json.loads(step2_response)
    
    # æ­¥éª¤ 3: åŒ¹é…å’Œè¯„åˆ†
    step3_response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[
            {
                "role": "system",
                "content": """Rate the match between candidate and job:
{
    "overall_match_score": 0-100,
    "matching_skills": [],
    "missing_skills": [],
    "recommendation": "strong_yes|yes|maybe|no"
}"""
            },
            {
                "role": "user",
                "content": f"Candidate: {json.dumps(candidate)}\n\nJob: {json.dumps(job)}"
            }
        ],
        response_format={"type": "json_object"}
    ).choices[0].message.content
    
    match = json.loads(step3_response)
    
    return {
        "candidate": candidate,
        "job": job,
        "match": match
    }
```

---

## ç¬¬å››éƒ¨åˆ†ï¼šå¤š LLM æä¾›å•†å¯¹æ¯” (0.5h)

| æä¾›å•† | æœ€å¼ºæ¨¡å‹ | æˆæœ¬ | ä¸Šä¸‹æ–‡ | æœ€ä½³ç”¨é€” |
|--------|--------|------|--------|--------|
| OpenAI | GPT-4 | $$ | 128K | å¤æ‚æ¨ç†ã€é«˜ç²¾åº¦ |
| Anthropic | Claude 3 Opus | $$ | 200K | é•¿æ–‡æœ¬åˆ†æã€æ³•å¾‹ |
| DeepSeek | DeepSeek-67B | $ | 4K | æˆæœ¬æ•æ„Ÿçš„ä»»åŠ¡ |
| Meta | Llama 3 | å…è´¹ (æœ¬åœ°) | 8K | éšç§æ•æ„Ÿã€ç¦»çº¿ |

### æˆæœ¬å¯¹æ¯”ï¼ˆå¤„ç† 100 ä¸‡å­—ï¼‰

```python
# å‡è®¾ 1 ç™¾ä¸‡å­—ï¼Œä»·æ ¼å¯¹æ¯”ï¼š

# OpenAI GPT-3.5-turbo
# è´¹ç”¨: $0.0015 * 100 ä¸‡ / 1000 = $150

# Claude 3 Haikuï¼ˆä¾¿å®œç‰ˆæœ¬ï¼‰
# è´¹ç”¨: $0.00025 * 100 ä¸‡ / 1000 = $25

# DeepSeek API
# è´¹ç”¨: $0.00003 * 100 ä¸‡ / 1000 = $3

# Llama 3 (æœ¬åœ° GPU)
# è´¹ç”¨: $0ï¼ˆä½ å·²ç»æœ‰ GPUï¼‰

# FDE å®è·µ: ä¾¿å®œçš„ä»»åŠ¡ç”¨ DeepSeekï¼Œå¤æ‚çš„ç”¨ GPT-4
```

---

## å®æˆ˜æ¡ˆä¾‹ï¼šæ„å»º"æ™ºèƒ½æ–‡æ¡£åŠ©æ‰‹"

```python
class SmartDocumentAssistant:
    def __init__(self, api_key):
        self.client = OpenAI(api_key=api_key)
    
    def process_document(self, doc_path):
        """å®Œæ•´çš„æ–‡æ¡£å¤„ç†æµç¨‹"""
        
        # 1. åŠ è½½æ–‡æ¡£
        with open(doc_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # 2. å¦‚æœå¤ªé•¿ï¼Œé‡‡æ ·å…³é”®éƒ¨åˆ†
        if len(content) > 5000:
            content = self._smart_sample(content)
        
        # 3. ç»“æ„åŒ–æå–
        extraction = self._extract_structure(content)
        
        # 4. åˆ†ç±»å’Œæ ‡ç­¾
        classification = self._classify(content, extraction)
        
        # 5. è¿”å›ç»“æœ
        return {
            "extraction": extraction,
            "classification": classification,
            "summary": extraction.get("summary", "")
        }
    
    def _smart_sample(self, text):
        """æ™ºèƒ½é‡‡æ ·"""
        lines = text.split('\n')
        # å–å¼€å¤´ã€ä¸­é—´ã€ç»“å°¾
        sampled = lines[:100] + lines[len(lines)//2-50:len(lines)//2+50] + lines[-100:]
        return '\n'.join(sampled)
    
    def _extract_structure(self, text):
        """æå–ç»“æ„åŒ–æ•°æ®"""
        response = self.client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {
                    "role": "system",
                    "content": """Extract document structure as JSON:
{
    "title": "",
    "main_sections": [],
    "key_concepts": [],
    "summary": "",
    "metadata": {"author": "", "date": ""}
}"""
                },
                {"role": "user", "content": f"Document:\n{text}"}
            ],
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
    
    def _classify(self, text, extraction):
        """åˆ†ç±»"""
        response = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "Classify the document type and importance"
                },
                {"role": "user", "content": f"Structure: {extraction}"}
            ]
        )
        return response.choices[0].message.content
```

---

## ç¬¬äºŒå¤©çš„æ£€æŸ¥æ¸…å•
- [ ] å†™è¿‡ 5 ä¸ªä¸åŒçš„ System Promptï¼Œçœ‹åˆ°äº†ä¸åŒçš„å›åº”
- [ ] æˆåŠŸå¤„ç†è¿‡è¶… 5000 å­—çš„æ–‡æœ¬
- [ ] ä½¿ç”¨äº† JSON Mode å¹¶è§£æäº†è¿”å›å€¼
- [ ] å¯¹æ¯”è¿‡ 2+ ä¸ª LLM æä¾›å•†
- [ ] èƒ½è§£é‡Šä¸ºä»€ä¹ˆæŸä¸ª System Prompt æ¯”å¦ä¸€ä¸ªæ›´å¥½

ğŸ‰ ç¬¬ 2 å¤©å®Œæˆï¼ç°åœ¨ä½ æ˜¯ API è°ƒç”¨é«˜æ‰‹ã€‚ä¸‹ä¸€æ­¥ï¼šStreamlit å¿«é€Ÿæ­ UIã€‚
