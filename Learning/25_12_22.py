"""
ğŸŸ¦ Day 1: RAG æ ¸å¿ƒæ¦‚å¿µå®ç°
æ—¥æœŸ: 2025-12-22
ä¸»é¢˜: RAG æœ€å°ç»“æ„ + 5ä¸ªå…³é”®è°ƒå‚å®æˆ˜

RAG å·¥ä½œæµ:
    æ–‡æ¡£ â†’ Chunk â†’ Embedding â†’ Vector DB
                        â†“
           ç”¨æˆ·é—®é¢˜ â†’ æ£€ç´¢ â†’ LLM â†’ å›ç­”
"""

import json
from typing import List, Dict, Tuple
import math


# ============================================================================
# ç¬¬ä¸€éƒ¨åˆ†: ç†è§£ Chunk Size çš„å½±å“
# ============================================================================

class ChunkDemo:
    """æ¼”ç¤º Chunk Size å¯¹æ•ˆæœçš„å½±å“"""
    
    def __init__(self):
        # æ¨¡æ‹Ÿæ³•å¾‹æ–‡æ¡£ï¼ˆå®Œæ•´çš„æ¡æ¬¾ï¼‰
        self.legal_document = """
        ç¬¬ä¸€ç«  æ€»åˆ™
        ç¬¬ä¸€æ¡ æœ¬å…¬å¸æ ¹æ®ã€Šä¸­åäººæ°‘å…±å’Œå›½å…¬å¸æ³•ã€‹å’Œå…¶ä»–ç›¸å…³æ³•å¾‹ã€æ³•è§„ç»„ç»‡ã€è¿è¥ã€‚
        ç¬¬äºŒæ¡ æœ¬å…¬å¸çš„æ³•å®šä»£è¡¨äººä¸ºè‘£äº‹é•¿ï¼Œå¯¹å…¬å¸è´Ÿè´£ã€‚
        ç¬¬ä¸‰æ¡ æœ¬å…¬å¸å®è¡Œè‘£äº‹é•¿è´Ÿè´£åˆ¶ï¼Œè‘£äº‹é•¿ä¸»æŒè‘£äº‹ä¼šå·¥ä½œã€‚
        
        ç¬¬äºŒç«  è‚¡ä¸œæƒåˆ©
        ç¬¬å››æ¡ è‚¡ä¸œäº«æœ‰ä»¥ä¸‹æƒåˆ©ï¼š
        ï¼ˆä¸€ï¼‰å‚åŠ æˆ–å§”æ‰˜ä»£ç†äººå‚åŠ è‚¡ä¸œä¼šï¼›
        ï¼ˆäºŒï¼‰è¡Œä½¿è¡¨å†³æƒï¼Œå¯¹å…¬å¸é‡å¤§äº‹é¡¹è¿›è¡Œè¡¨å†³ï¼›
        ï¼ˆä¸‰ï¼‰æŸ¥é˜…å…¬å¸æ–‡ä»¶å’Œè®°å½•ï¼›
        ï¼ˆå››ï¼‰åˆ†å–çº¢åˆ©æˆ–åˆ†é…å‰©ä½™è´¢äº§ï¼›
        ï¼ˆäº”ï¼‰ä¾æ³•è½¬è®©å‡ºèµ„æˆ–è‚¡æƒï¼›
        ï¼ˆå…­ï¼‰æè®®å¬å¼€ä¸´æ—¶è‚¡ä¸œä¼šã€‚
        """
    
    def chunk_strategy_1_small(self) -> List[str]:
        """ç­–ç•¥1: å°å— (256 tokens) - çº¦ 30-50 è¯"""
        chunks = []
        sentences = self.legal_document.split('ã€‚')
        
        current_chunk = ""
        for sentence in sentences:
            if len(current_chunk) < 50:  # ç®€åŒ–: æŒ‰å­—ç¬¦é•¿åº¦
                current_chunk += sentence + "ã€‚"
            else:
                if current_chunk.strip():
                    chunks.append(current_chunk)
                current_chunk = sentence + "ã€‚"
        
        if current_chunk.strip():
            chunks.append(current_chunk)
        
        return chunks
    
    def chunk_strategy_2_medium(self) -> List[str]:
        """ç­–ç•¥2: ä¸­å— (512 tokens) - æ®µè½çº§åˆ«"""
        chunks = []
        paragraphs = self.legal_document.split('\n\n')
        
        for para in paragraphs:
            if para.strip():
                chunks.append(para.strip())
        
        return chunks
    
    def chunk_strategy_3_large(self) -> List[str]:
        """ç­–ç•¥3: å¤§å— (1024+ tokens) - å®Œæ•´ç« èŠ‚"""
        return [self.legal_document.strip()]
    
    def demonstrate(self):
        """æ¼”ç¤ºä¸‰ç§ç­–ç•¥çš„åŒºåˆ«"""
        print("\n" + "="*70)
        print("æ¼”ç¤º: Chunk Size å¯¹æ£€ç´¢æ•ˆæœçš„å½±å“")
        print("="*70)
        
        small = self.chunk_strategy_1_small()
        medium = self.chunk_strategy_2_medium()
        large = self.chunk_strategy_3_large()
        
        print(f"\nâœ“ å°å—ç­–ç•¥ (256 tokens):")
        print(f"  - å—æ•°: {len(small)}")
        print(f"  - ä¼˜ç‚¹: ç²¾å‡†åº¦é«˜ âœ“")
        print(f"  - ç¼ºç‚¹: å¯èƒ½ç¢ç‰‡åŒ–ã€ä¸¢å¤±é€»è¾‘è¿è´¯æ€§ âœ—")
        print(f"  - ç¤ºä¾‹å—:\n    '{small[0][:60]}...'")
        
        print(f"\nâœ“ ä¸­å—ç­–ç•¥ (512 tokens):")
        print(f"  - å—æ•°: {len(medium)}")
        print(f"  - ä¼˜ç‚¹: å¹³è¡¡ç²¾å‡†åº¦ä¸ä¸Šä¸‹æ–‡ âœ“")
        print(f"  - ç¼ºç‚¹: éœ€è¦ä»”ç»†è°ƒä¼˜")
        print(f"  - ç¤ºä¾‹å—:\n    '{medium[0][:60]}...'")
        
        print(f"\nâœ“ å¤§å—ç­–ç•¥ (1024+ tokens):")
        print(f"  - å—æ•°: {len(large)}")
        print(f"  - ä¼˜ç‚¹: ä¿ç•™å®Œæ•´é€»è¾‘ âœ“âœ“")
        print(f"  - ç¼ºç‚¹: å™ªéŸ³å¤šã€æˆæœ¬é«˜ âœ—")
        print(f"  - ç”¨é€”: æ³•å¾‹/åŒ»ç–—ç­‰éœ€è¦é€»è¾‘è¿è´¯çš„æ–‡æ¡£")


# ============================================================================
# ç¬¬äºŒéƒ¨åˆ†: æ¨¡æ‹Ÿ Embedding å’Œç›¸ä¼¼åº¦è®¡ç®—
# ============================================================================

class SimpleEmbedding:
    """ç®€å•çš„ Embedding æ¨¡æ‹Ÿï¼ˆå®é™…ä¼šç”¨ OpenAI/Qwenï¼‰"""
    
    @staticmethod
    def simple_hash_embed(text: str, dim: int = 8) -> List[float]:
        """
        ç®€åŒ–ç‰ˆ embedding: ç”¨æ–‡æœ¬ç‰¹å¾ç”Ÿæˆå‘é‡
        å®é™…åº”ç”¨ä¼šç”¨ï¼š
        - OpenAI Embedding API (1536 dim)
        - å¼€æºæ¨¡å‹: bge-base-zh (768 dim)
        - è½»é‡çº§: m3e-small (384 dim)
        """
        # è®¡ç®—æ–‡æœ¬çš„å‡ ä¸ªç‰¹å¾
        features = []
        
        # ç‰¹å¾1: æ–‡æœ¬é•¿åº¦
        features.append(len(text) % 10 / 10.0)
        
        # ç‰¹å¾2: å…ƒéŸ³æ¯”ä¾‹
        vowels = sum(1 for c in text if c in 'aeiouAEIOU')
        features.append(vowels / max(len(text), 1) / 10.0)
        
        # ç‰¹å¾3: æ•°å­—æ¯”ä¾‹
        digits = sum(1 for c in text if c.isdigit())
        features.append(digits / max(len(text), 1) / 10.0)
        
        # ç‰¹å¾4-8: è¯é¢‘ç‰¹å¾
        for char in ['a', 'e', 'i']:
            count = text.lower().count(char)
            features.append(count % 5 / 5.0)
        
        # è¡¥é½ç»´åº¦
        while len(features) < dim:
            features.append(0.5)
        
        return features[:dim]
    
    @staticmethod
    def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ (0-1)"""
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        norm1 = math.sqrt(sum(a ** 2 for a in vec1))
        norm2 = math.sqrt(sum(b ** 2 for b in vec2))
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def demonstrate(self):
        """æ¼”ç¤º Embedding å’Œç›¸ä¼¼åº¦"""
        print("\n" + "="*70)
        print("æ¼”ç¤º: Embedding å’Œç›¸ä¼¼åº¦è®¡ç®—")
        print("="*70)
        
        # ä¸‰ä¸ªæ ·æœ¬æ–‡æœ¬
        texts = [
            "å…¬å¸ 2024 å¹´è¥æ”¶å¢é•¿ 30%",
            "ä»Šå¹´çš„é”€å”®é¢ç›¸æ¯”å»å¹´æå‡ä¸‰æˆ",
            "æˆ‘æœ€è¿‘å»æ—…æ¸¸äº†å¾ˆå¼€å¿ƒ"
        ]
        
        print("\næ–‡æœ¬ 1 å’Œ 2 åº”è¯¥ç›¸ä¼¼ (éƒ½æ˜¯è¯´è¥æ”¶å¢é•¿)")
        print("æ–‡æœ¬ 1 å’Œ 3 åº”è¯¥ä¸ç›¸ä¼¼ (ä¸åŒä¸»é¢˜)\n")
        
        embeddings = [self.simple_hash_embed(text) for text in texts]
        
        sim_1_2 = self.cosine_similarity(embeddings[0], embeddings[1])
        sim_1_3 = self.cosine_similarity(embeddings[0], embeddings[2])
        
        print(f"ç›¸ä¼¼åº¦ (æ–‡æœ¬1 vs æ–‡æœ¬2): {sim_1_2:.3f} âœ“ åº”è¯¥è¾ƒé«˜")
        print(f"ç›¸ä¼¼åº¦ (æ–‡æœ¬1 vs æ–‡æœ¬3): {sim_1_3:.3f} âœ“ åº”è¯¥è¾ƒä½")
        
        print(f"\nğŸ’¡ å…³é”®è®¤çŸ¥:")
        print(f"   å°æ¨¡å‹ (384 dim) vs å¤§æ¨¡å‹ (1536 dim)")
        print(f"   - å¯¹å¤§å¤šæ•°åœºæ™¯: å·®å¼‚ < 10%")
        print(f"   - æˆæœ¬å·®å¼‚: 10 å€ä»¥ä¸Š")
        print(f"   - æ¨è: å…ˆç”¨ä¸­ç­‰æ¨¡å‹ (768 dim) è°ƒè¯•")


# ============================================================================
# ç¬¬ä¸‰éƒ¨åˆ†: Top-K æ£€ç´¢å’Œå¹»è§‰åˆ†æ
# ============================================================================

class TopKRetrieval:
    """æ¼”ç¤º Top-K å¯¹æ£€ç´¢ç»“æœå’Œå¹»è§‰çš„å½±å“"""
    
    def __init__(self):
        # æ¨¡æ‹Ÿå‘é‡æ•°æ®åº“: (æ–‡æ¡£å—, ç›¸ä¼¼åº¦)
        self.documents = [
            ("å…¬å¸æˆç«‹äº 2018 å¹´ï¼Œæ€»éƒ¨åœ¨åŒ—äº¬", 0.95),
            ("2024 å¹´å‘˜å·¥æ€»æ•° 500 äºº", 0.92),
            ("å…¬å¸ä¸»è¦äº§å“æ˜¯ AI ä¸­å°", 0.88),
            ("æœˆè¥æ”¶çº¦ 500 ä¸‡äººæ°‘å¸", 0.75),
            ("CEO æ¯•ä¸šäºæ¸…åå¤§å­¦", 0.60),
            ("åŠå…¬å®¤åœ¨ä¸­å…³æ‘åˆ›ä¸šå¤§è¡—", 0.45),
            ("é£Ÿå ‚æ¯å‘¨ä¸€æä¾›å…è´¹æ—©é¤", 0.20),  # æ˜æ˜¾ä¸ç›¸å…³
        ]
    
    def retrieve_top_k(self, k: int) -> Tuple[List[Tuple[str, float]], float]:
        """
        æ£€ç´¢ç›¸ä¼¼åº¦æœ€é«˜çš„ K ä¸ªæ–‡æ¡£
        è¿”å›: (æ£€ç´¢ç»“æœ, å¹³å‡ç›¸ä¼¼åº¦)
        """
        sorted_docs = sorted(self.documents, key=lambda x: x[1], reverse=True)
        top_k = sorted_docs[:k]
        
        avg_similarity = sum(sim for _, sim in top_k) / len(top_k) if top_k else 0
        
        return top_k, avg_similarity
    
    def analyze_hallucination(self, top_k: List[Tuple[str, float]]) -> Dict:
        """åˆ†æå¹»è§‰é£é™©"""
        if not top_k:
            return {"risk": "HIGH", "reason": "æ²¡æœ‰æ£€ç´¢ç»“æœ"}
        
        avg_sim = sum(sim for _, sim in top_k) / len(top_k)
        min_sim = min(sim for _, sim in top_k)
        
        if min_sim < 0.5:
            risk = "HIGH"
            reason = "åŒ…å«ä¸ç›¸å…³æ–‡æ¡£ï¼ŒLLM å®¹æ˜“æ··æ·†"
        elif avg_sim > 0.8:
            risk = "LOW"
            reason = "ç»“æœç›¸å…³æ€§é«˜ï¼ŒLLM å¯ä¿¡åº¦é«˜"
        else:
            risk = "MEDIUM"
            reason = "æœ‰ä¸€å®šç›¸å…³æ€§ï¼Œä½†éœ€è¦è°¨æ…"
        
        return {
            "risk": risk,
            "avg_similarity": round(avg_sim, 3),
            "min_similarity": round(min_sim, 3),
            "reason": reason
        }
    
    def demonstrate(self):
        """æ¼”ç¤ºä¸åŒ K å€¼çš„å½±å“"""
        print("\n" + "="*70)
        print("æ¼”ç¤º: Top-K å¯¹æ£€ç´¢å’Œå¹»è§‰çš„å½±å“")
        print("="*70)
        
        for k in [1, 3, 5, 10]:
            results, avg_sim = self.retrieve_top_k(k)
            hallucination = self.analyze_hallucination(results)
            
            print(f"\n{'â”€'*70}")
            print(f"K = {k} æ—¶çš„æ£€ç´¢ç»“æœ:")
            print(f"{'â”€'*70}")
            
            for i, (doc, sim) in enumerate(results, 1):
                print(f"  {i}. [{sim:.2f}] {doc}")
            
            print(f"\nå¹»è§‰åˆ†æ:")
            print(f"  - é£é™©ç­‰çº§: {hallucination['risk']}")
            print(f"  - å¹³å‡ç›¸ä¼¼åº¦: {hallucination['avg_similarity']}")
            print(f"  - æœ€ä½ç›¸ä¼¼åº¦: {hallucination['min_similarity']}")
            print(f"  - åˆ†æ: {hallucination['reason']}")


# ============================================================================
# ç¬¬å››éƒ¨åˆ†: RAG é€‚ç”¨æ€§åˆ¤æ–­
# ============================================================================

class RAGSuitability:
    """åˆ¤æ–­é—®é¢˜æ˜¯å¦é€‚åˆç”¨ RAG"""
    
    SUITABLE_CASES = {
        "åŸºäºæ–‡æ¡£çš„äº‹å®æŸ¥è¯¢": {
            "ç¤ºä¾‹": "å…¬å¸ 2024 å¹´è¥æ”¶æ˜¯å¤šå°‘ï¼Ÿ",
            "why": "ç­”æ¡ˆåœ¨æ–‡æ¡£é‡Œï¼ŒRAG å¯ä»¥ç²¾ç¡®æ£€ç´¢",
            "é€‚åˆ": True
        },
        "è·¨æ–‡æ¡£ç»¼åˆ": {
            "ç¤ºä¾‹": "å¯¹æ¯” A å’Œ B äº§å“çš„åŠŸèƒ½å·®å¼‚",
            "why": "éœ€è¦ä»å¤šä»½æ–‡æ¡£ä¸­æå–ä¿¡æ¯",
            "é€‚åˆ": True
        },
        "éœ€è¦æº¯æº/å¼•ç”¨": {
            "ç¤ºä¾‹": "è¿™æ¡æ”¿ç­–åœ¨å“ªä¸€ä»½æ–‡ä»¶çš„ç¬¬å‡ æ¡ï¼Ÿ",
            "why": "å¿…é¡»æŒ‡å‡ºæ¥æºï¼ŒRAG å¤©ç„¶æ”¯æŒ",
            "é€‚åˆ": True
        }
    }
    
    UNSUITABLE_CASES = {
        "å¤æ‚å¤šæ­¥æ¨ç†": {
            "ç¤ºä¾‹": "å¸®æˆ‘è®¾è®¡ä¸€ä¸ªè¥é”€ç­–ç•¥",
            "why": "éœ€è¦ Agentï¼ˆå¤šæ­¥æ¨ç†ï¼‰",
            "é€‚åˆ": False
        },
        "å®æ—¶äº¤äº’": {
            "ç¤ºä¾‹": "æŸ¥ä¸€ä¸‹ç°åœ¨çš„è‚¡ç¥¨ä»·æ ¼",
            "why": "éœ€è¦ Tool Calling + API",
            "é€‚åˆ": False
        },
        "åˆ›æ„ç”Ÿæˆ": {
            "ç¤ºä¾‹": "å¸®æˆ‘å†™ä¸€ä¸ªäº§å“å¹¿å‘Šæ–‡æ¡ˆ",
            "why": "éœ€è¦å¾®è°ƒæˆ–æ›´å¼ºçš„ prompt",
            "é€‚åˆ": False
        }
    }
    
    @staticmethod
    def judge(question: str) -> Dict:
        """åˆ¤æ–­ä¸€ä¸ªé—®é¢˜æ˜¯å¦é€‚åˆ RAG"""
        keywords_rag = ["æŸ¥è¯¢", "æ–‡æ¡£", "æ˜¯ä»€ä¹ˆ", "å“ªé‡Œ", "å¤šå°‘", "åˆ—å‡º", "æ€»ç»“"]
        keywords_no = ["è®¾è®¡", "åˆ›ä½œ", "å†™", "å®æ—¶", "ç°åœ¨", "æœ€æ–°", "ä»£ç æ‰§è¡Œ"]
        
        rag_score = sum(1 for kw in keywords_rag if kw in question)
        no_score = sum(1 for kw in keywords_no if kw in question)
        
        if rag_score > no_score:
            return {"suitable": True, "confidence": min(rag_score / 3, 1.0)}
        else:
            return {"suitable": False, "confidence": min(no_score / 3, 1.0)}
    
    def demonstrate(self):
        """æ¼”ç¤º RAG é€‚ç”¨æ€§åˆ¤æ–­"""
        print("\n" + "="*70)
        print("æ¼”ç¤º: RAG é€‚ç”¨æ€§åˆ¤æ–­ (FDE çš„æ•‘å‘½æŠ€èƒ½)")
        print("="*70)
        
        print("\nâœ… RAG é€‚åˆçš„åœºæ™¯:")
        print("â”€"*70)
        for case, info in self.SUITABLE_CASES.items():
            print(f"\nğŸ“Œ {case}")
            print(f"   ä¾‹å­: {info['ç¤ºä¾‹']}")
            print(f"   åŸå› : {info['why']}")
        
        print("\n\nâŒ RAG ä¸é€‚åˆçš„åœºæ™¯:")
        print("â”€"*70)
        for case, info in self.UNSUITABLE_CASES.items():
            print(f"\nğŸ“Œ {case}")
            print(f"   ä¾‹å­: {info['ç¤ºä¾‹']}")
            print(f"   åŸå› : {info['why']}")
        
        # æµ‹è¯•å‡ ä¸ªé—®é¢˜
        print("\n\nğŸ§ª ç¤ºä¾‹é—®é¢˜åˆ¤æ–­:")
        print("â”€"*70)
        test_questions = [
            "æˆ‘ä»¬å…¬å¸çš„äº§å“éƒ½æœ‰å“ªäº›åŠŸèƒ½ï¼Ÿ",
            "å¸®æˆ‘å†™ä¸€ä¸ªäº§å“æ¨ä»‹è¯",
            "æŸ¥ä¸€ä¸‹åˆåŒæ¡æ¬¾é‡Œçš„é€€æ¬¾æ”¿ç­–"
        ]
        
        for q in test_questions:
            result = self.judge(q)
            suitable = "âœ“ é€‚åˆ RAG" if result['suitable'] else "âœ— ä¸é€‚åˆ RAG"
            print(f"\nQ: {q}")
            print(f"A: {suitable} (ç½®ä¿¡åº¦: {result['confidence']:.1%})")


# ============================================================================
# ä¸»å‡½æ•°: è¿è¡Œå…¨éƒ¨æ¼”ç¤º
# ============================================================================

def main():
    print("\n" + "ğŸ”µ"*35)
    print("ğŸŸ¦ RAG Day 1: æ ¸å¿ƒæ¦‚å¿µå®Œå…¨æ¼”ç¤º ğŸŸ¦")
    print("ğŸ”µ"*35)
    
    # æ¼”ç¤º 1: Chunk Size
    chunk_demo = ChunkDemo()
    chunk_demo.demonstrate()
    
    # æ¼”ç¤º 2: Embedding
    embedding_demo = SimpleEmbedding()
    embedding_demo.demonstrate()
    
    # æ¼”ç¤º 3: Top-K å’Œå¹»è§‰
    topk_demo = TopKRetrieval()
    topk_demo.demonstrate()
    
    # æ¼”ç¤º 4: RAG é€‚ç”¨æ€§
    suitability_demo = RAGSuitability()
    suitability_demo.demonstrate()
    
    print("\n" + "="*70)
    print("âœ… Day 1 å­¦ä¹ å®Œæˆ!")
    print("="*70)
    print("""
ğŸ“‹ Day 1 å…³é”®æ£€æŸ¥æ¸…å•:
  â˜ èƒ½è§£é‡Š RAG çš„ 6 æ­¥å·¥ä½œæµ
  â˜ çŸ¥é“ Chunk Size çš„ 3 ç§ç­–ç•¥
  â˜ ç†è§£ Embedding çš„ä½œç”¨
  â˜ èƒ½åˆ¤æ–­æœ€ä¼˜çš„ Top-K å€¼
  â˜ çŸ¥é“ RAG çš„é€‚ç”¨å’Œä¸é€‚ç”¨åœºæ™¯

ğŸ¬ ä¸‹ä¸€æ­¥: è¿›å…¥ Day 2 - ToB åœºæ™¯ä¸‹çš„ RAG å·®å¼‚åŒ–è®¾è®¡
    """)


if __name__ == "__main__":
    main()
