# 🟦 RAG 快速参考卡片（放在你的口袋里）

## 1️⃣ RAG 工作流（30秒版）

```
文档 → 分块 → 嵌入向量 → 向量库
                ↓
            用户问题 → 检索 → LLM → 答案
```

**一句话**: "AI 先读你的文档，再回答问题"

---

## 2️⃣ 5 个关键参数速查表

| 参数 | 小 | 中 | 大 | 建议 |
|------|----|----|----|----|
| **Chunk Size** | 256 tok | 512 tok | 1024 tok | 512-768 |
| **Embedding 维度** | 384 dim | 768 dim | 1536 dim | 768 优先 |
| **Top-K** | K=1 | K=5 | K=10 | K=3-5 |
| **相似度阈值** | > 0.5 | > 0.7 | > 0.85 | 按场景 |
| **更新频率** | 每月 | 每周 | 每天 | 业务决定 |

---

## 3️⃣ 5 问诊断速查表

在听完 15 分钟业务后，问这 5 个问题：

```
1️⃣ 文档在哪？什么格式？
   → 决定数据处理复杂度

2️⃣ 多久更新一次？
   → 决定索引更新策略

3️⃣ 谁用？员工还是客户？
   → 决定权限隔离方案

4️⃣ 错一次能接受吗？
   → 决定验证和审核流程

5️⃣ 需要溯源吗？
   → 决定是否需要完整审计日志
```

---

## 4️⃣ 适用性判断（快速）

### ✅ RAG 很适合
- [ ] 基于文档的事实查询
- [ ] 需要指出来源
- [ ] 跨多个文件找答案
- [ ] 文档频繁更新

### ❌ RAG 不适合
- [ ] 复杂多步推理 → 用 Agent
- [ ] 代码执行 → 用 Tool Calling
- [ ] 创意生成 → 用微调
- [ ] 实时数据 → 用 API

---

## 5️⃣ Demo 标准流程（5分钟）

```
1. 原始问题设定 (30秒)
   "你们现在怎么查这个信息？"

2. 无 RAG 演示 (1分钟)
   问 LLM → 泛泛而谈 ❌

3. 有 RAG 演示 (2分钟)
   检索 + 问 LLM → 准确答案 ✅

4. 总结 (30秒)
   "不是模型更聪明，是它终于能看你们的数据了"

5. 回答问题 (1分钟)
   创始人问的 3-5 个问题
```

**成功标志**: 创始人问"什么时候开始"

---

## 6️⃣ 常见错误及修正

### ❌ 错误 1: 忽视 Chunk Size
```
症状: "为什么答案不相关？"
原因: Chunk 太小 → 丢失上下文 或 Chunk 太大 → 噪音太多
修正: 从 512 开始，逐步调整
```

### ❌ 错误 2: 盲目用大模型
```
症状: "成本很高，速度很慢"
原因: 用 1536 维 Embedding，实际不需要
修正: 先用 768 维，有问题再升级
```

### ❌ 错误 3: Top-K 设置不对
```
症状: "答案混乱，幻觉很多"
原因: K=10+ 引入了不相关文档
修正: K=3-5，问题复杂再增加
```

### ❌ 错误 4: 忽视权限隔离
```
症状: "SaaS 中客户 A 看到了客户 B 的数据"
原因: 单一索引，没有隔离
修正: 每个租户独立索引或加 metadata 过滤
```

### ❌ 错误 5: 过度宣传能力
```
症状: "客户发现系统会编造信息"
原因: 没有明确告诉用户哪些场景有风险
修正: 透明说明限制，设置相似度阈值
```

---

## 7️⃣ 行业速查表

| 行业 | 核心挑战 | Chunk | Top-K | 相似度 | 关键 |
|-----|---------|-------|-------|--------|------|
| **SaaS** | 多租户隔离 | 中 | 5 | 0.7 | 权限 |
| **制造** | PDF/图纸 | 大 | 3 | 0.75 | OCR |
| **法律** | 精确溯源 | 小 | 3 | 0.85 | 审计 |
| **医疗** | 低幻觉 | 中 | 3 | 0.9 | 安全 |
| **Wiki** | 快速更新 | 小 | 5 | 0.7 | 实时 |

---

## 8️⃣ 创始人常问的 5 个问题 & 回答

```
Q1: "这个系统多快？"
A: "平均检索 < 100ms，支持每秒 1000+ 并发"

Q2: "准确率是多少？"
A: "Top-5 准确率 95%+，关键是选对参数"

Q3: "费用多少？"
A: "取决于文档量和并发数，从 3000 元/月 起"

Q4: "多久能部署？"
A: "POC 2-3 周，完整系统 4-6 周"

Q5: "能处理我们的特殊格式吗？"
A: "通常可以，我看看你的文档再给确切答案"
```

---

## 9️⃣ 成本评估速查

**一个 SaaS RAG 系统的月成本**:

```
基础成本:
├── Embedding API (OpenAI): 按使用量 ~100-500 元/月
├── 向量数据库 (Milvus 自建): ~0 (开源) 或 Pinecone ~500 元/月
├── LLM API (Qwen/GPT): ~1000-5000 元/月
└── 服务器: ~1000 元/月

推荐配置:
- Embedding: 开源 (m3e/bge) 或 Qwen Embedding
- Vector DB: Milvus 自建 (省钱)
- LLM: Qwen API (便宜) 或 OpenAI (贵但好用)

成本: 总体 2000-8000 元/月 (取决于规模)
```

---

## 🔟 30 秒内判断一个问题

```
问题 → 问自己 → 答案

"这适合 RAG 吗？"
  ↓
  需要从文档里找答案吗？ → YES → RAG 很适合
  ↓ NO
  需要多步推理吗？ → YES → 用 Agent
  ↓ NO
  需要调用外部系统吗？ → YES → 用 Tool Calling
  ↓ NO
  需要完全创新内容吗？ → YES → 用微调
  ↓ NO
  → 基础 LLM 就够了
```

---

## 快速备忘单 (放在手机里)

### Demo 演讲词
```
"问题是，你们的知识在文档里，
但 AI 看不到。

我们用 RAG，让 AI 先读你们的文档，
再回答问题。

看，同样的问题：
- 没有 RAG: 很泛 ❌
- 有 RAG: 准确 ✅

这就是价值。"
```

### 技术总结
```
RAG = 检索 (Retrieval) + 增强 (Augmentation) + 生成 (Generation)

检索: 从向量库找相关文档
增强: 把文档加到 LLM 的输入里
生成: LLM 基于增强后的输入生成答案
```

### 风险提示
```
RAG 的风险:
1. 文档质量差 → 垃圾进垃圾出
2. 隐私泄露 → 多租户隔离不好
3. 幻觉 → 检索结果不相关
4. 维护成本 → 文档要持续更新

每个风险都有应对方案，但要提前考虑。
```

---

## 一页纸总结 (打印给客户)

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
                  什么是 RAG？
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

RAG = 让 AI 读你的文档，然后回答问题

工作原理:
1️⃣ 文档分块 → 2️⃣ 转化为向量 → 3️⃣ 存入向量库
4️⃣ 用户提问 → 5️⃣ 从库中检索相关内容 → 6️⃣ AI 生成答案

为什么需要 RAG？

❌ 没有 RAG:
   AI: "我不知道你们的情况，请咨询销售..."
   
✅ 有了 RAG:
   AI: "根据你们的内部文档，答案是..."

三个价值:
✓ 准确 - 答案基于你的实际数据
✓ 快速 - 几周就能看到效果  
✓ 可追溯 - 每个答案都有出处

适用场景:
√ 产品文档查询    √ 员工知识库    √ 法律文件查询
√ 客户问答        √ 规章制度查询  √ 合同条款查询

不适用场景:
✗ 需要代码执行    ✗ 需要创意生成  ✗ 需要复杂推理

成本:
大约 3000-10000 元/月 (取决于规模)

时间:
POC: 2-3 周  |  完整上线: 4-6 周

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

---

## 更新日志

| 日期 | 版本 | 更新 |
|------|------|------|
| 2025-12-22 | 1.0 | 首次发布 |

**需要帮助?** 回到 [README.md](README.md) 看完整文档
