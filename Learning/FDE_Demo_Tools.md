# ğŸ¨ FDE Demo Tools é€ŸæŸ¥æŒ‡å—
## Streamlit / Chainlit å¿«é€Ÿä¸Šæ‰‹ (Day 2-3)

**ç›®æ ‡**ï¼šç”¨ Streamlit åœ¨ 2 å°æ—¶å†…å†™å‡ºèƒ½å±•ç¤ºç»™å®¢æˆ·çš„åŸå‹

**ä¸ºä»€ä¹ˆé‡è¦**ï¼š
- FDE çš„æœ€é«˜å¢ƒç•Œ = ç”¨æœ€å°‘çš„ä»£ç ç”Ÿæˆæœ€å¤šçš„ä»·å€¼
- ä¸€ä¸ªå¥½çš„ UI æ¯” 100 è¡Œä¼˜é›…çš„ä»£ç æ›´èƒ½æ‰“åŠ¨æŠ•èµ„äºº
- å®¢æˆ·ä¸å…³å¿ƒåç«¯å®ç°ï¼Œåªå…³å¿ƒèƒ½å¦ç”¨ã€èƒ½å¦æ¼”ç¤º

---

## ğŸ“¦ å¿«é€Ÿå®‰è£…

```bash
# æ¨èæ–¹å¼ï¼šç”¨ç‹¬ç«‹è™šæ‹Ÿç¯å¢ƒ
conda create -n streamlit-env python=3.11 -y
conda activate streamlit-env

# å®‰è£…ä¾èµ–ï¼ˆæ ¹æ®ä½ çš„é¡¹ç›®é€‰æ‹©ï¼‰
pip install streamlit         # åŸºç¡€ç‰ˆ
pip install streamlit chainlit    # ä¸¤ä¸ªéƒ½è¦
pip install streamlit pandas numpy requests python-dotenv
```

**æ£€æŸ¥å®‰è£…**ï¼š
```bash
streamlit --version
# åº”è¯¥è¾“å‡ºç±»ä¼¼ï¼šStreamlit, version 1.28.0
```

---

## ğŸš€ ä¸€ä¸ª 5 åˆ†é’Ÿçš„ Streamlit Demo

### æœ€å°åŒ–ç¤ºä¾‹ï¼ˆ10 è¡Œä»£ç ï¼‰

**æ–‡ä»¶**: `hello_streamlit.py`
```python
import streamlit as st

st.set_page_config(page_title="FAQ Bot", layout="wide")

st.title("ğŸ¤– ç®€å•é—®ç­”æœºå™¨äºº")

# ç”¨æˆ·è¾“å…¥
user_question = st.text_input("é—®æˆ‘ä¸€ä¸ªé—®é¢˜ï¼š")

if user_question:
    st.success(f"ä½ é—®ï¼š{user_question}")
    st.info("æˆ‘æ˜¯ä¸€ä¸ªç®€å•çš„å›å¤æœºå™¨äººã€‚å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨ LLM API")
```

**è¿è¡Œ**ï¼š
```bash
streamlit run hello_streamlit.py
```

**ç°è±¡**ï¼š
- è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ `http://localhost:8501`
- å¯ä»¥å®æ—¶äº¤äº’
- ä¿®æ”¹ä»£ç ä¼šè‡ªåŠ¨åˆ·æ–°ï¼ˆè¶…çº§å¿«ï¼ï¼‰

---

## ğŸ¯ å®Œæ•´çš„ FAQ Bot Demoï¼ˆå®æˆ˜çº§ï¼‰

**æ–‡ä»¶**: `faq_bot.py`

```python
import streamlit as st
import os
from dotenv import load_dotenv
from openai import OpenAI

# ============ é…ç½®éƒ¨åˆ† ============
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

st.set_page_config(page_title="ä¼ä¸š FAQ Bot", layout="wide", initial_sidebar_state="expanded")

# ============ ä¾§è¾¹æ é…ç½® ============
with st.sidebar:
    st.title("âš™ï¸ é…ç½®")
    
    model = st.selectbox(
        "é€‰æ‹© LLM æ¨¡å‹",
        ["gpt-4-turbo", "gpt-3.5-turbo"]
    )
    
    temperature = st.slider(
        "å›ç­”åˆ›æ„ç¨‹åº¦",
        min_value=0.0,
        max_value=2.0,
        value=0.7,
        step=0.1
    )
    
    system_prompt = st.text_area(
        "ç³»ç»Ÿæç¤ºè¯",
        value="ä½ æ˜¯ä¸€ä¸ªä¼ä¸š FAQ åŠ©æ‰‹ã€‚ç”¨ç®€æ´ã€ä¸“ä¸šçš„è¯­è¨€å›ç­”é—®é¢˜ã€‚",
        height=100
    )
    
    st.markdown("---")
    st.write("ğŸ“Š ä½¿ç”¨ç»Ÿè®¡")
    st.write(f"âœ… å·²å›ç­”é—®é¢˜ï¼š{st.session_state.get('question_count', 0)}")

# ============ ä¸»ç•Œé¢ ============
st.title("ğŸ’¼ ä¼ä¸š FAQ é—®ç­”ç³»ç»Ÿ")
st.markdown("è¾“å…¥ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šä¸ºä½ æä¾›ç­”æ¡ˆã€‚")

# ============ èŠå¤©å†å²ï¼ˆä½¿ç”¨ Session Stateï¼‰============
if "messages" not in st.session_state:
    st.session_state.messages = []
if "question_count" not in st.session_state:
    st.session_state.question_count = 0

# ============ æ˜¾ç¤ºå†å²æ¶ˆæ¯ ============
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ============ ç”¨æˆ·è¾“å…¥ ============
if prompt := st.chat_input("é—®æˆ‘ä»€ä¹ˆå§..."):
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # åŠ å…¥å†å²
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # è°ƒç”¨ API
    with st.spinner("ğŸ”„ æ€è€ƒä¸­..."):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    *st.session_state.messages
                ],
                temperature=temperature,
                max_tokens=1000
            )
            
            assistant_message = response.choices[0].message.content
            
            # æ˜¾ç¤ºåŠ©æ‰‹å›å¤
            with st.chat_message("assistant"):
                st.markdown(assistant_message)
            
            # ä¿å­˜åˆ°å†å²
            st.session_state.messages.append({
                "role": "assistant",
                "content": assistant_message
            })
            
            # æ›´æ–°è®¡æ•°
            st.session_state.question_count += 1
            
        except Exception as e:
            st.error(f"âŒ å‡ºé”™äº†ï¼š{str(e)}")
            st.warning("ğŸ’¡ æç¤ºï¼šæ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ API Key æ˜¯å¦æ­£ç¡®")

# ============ é¡µè„š ============
st.markdown("---")
col1, col2, col3 = st.columns(3)
with col1:
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯"):
        st.session_state.messages = []
        st.session_state.question_count = 0
        st.rerun()

with col2:
    if st.button("ğŸ“‹ å¯¼å‡ºå¯¹è¯"):
        conversation_text = "\n\n".join([
            f"**{msg['role'].upper()}**: {msg['content']}"
            for msg in st.session_state.messages
        ])
        st.download_button(
            label="ä¸‹è½½ Markdown",
            data=conversation_text,
            file_name="conversation.md",
            mime="text/markdown"
        )

st.caption("ğŸš€ FDE Demo - å±•ç¤ºä¼ä¸šçº§ AI èƒ½åŠ›")
```

**è¿è¡Œ**ï¼š
```bash
# ç¡®ä¿ .env æœ‰ OPENAI_API_KEY
streamlit run faq_bot.py
```

**å…³é”®ç‰¹æ€§**ï¼š
- âœ… èŠå¤©å†å²ä¿ç•™ï¼ˆç”¨ `st.session_state`ï¼‰
- âœ… ä¾§è¾¹æ é…ç½®ï¼ˆæ¸©åº¦ã€Model é€‰æ‹©ï¼‰
- âœ… é”™è¯¯å¤„ç†ï¼ˆAPI å¤±è´¥æ—¶æœ‰å‹å¥½æç¤ºï¼‰
- âœ… å¯¼å‡ºåŠŸèƒ½ï¼ˆå®¢æˆ·å¯ä»¥ä¸‹è½½å¯¹è¯ï¼‰
- âœ… è®¡æ•°ç»Ÿè®¡ï¼ˆå±•ç¤º"å·²å›ç­” 10 ä¸ªé—®é¢˜"ä¹‹ç±»ï¼‰

---

## ğŸ”§ Streamlit æ ¸å¿ƒç»„ä»¶é€ŸæŸ¥è¡¨

### è¾“å…¥ç»„ä»¶
```python
# æ–‡æœ¬è¾“å…¥ï¼ˆå•è¡Œï¼‰
name = st.text_input("ä½ çš„åå­—")

# æ–‡æœ¬è¾“å…¥ï¼ˆå¤šè¡Œï¼‰
description = st.text_area("æè¿°")

# é€‰æ‹©æ¡†
option = st.selectbox("é€‰æ‹©ä¸€ä¸ª", ["é€‰é¡¹ 1", "é€‰é¡¹ 2"])

# å¤šé€‰
choices = st.multiselect("å¤šé€‰", ["A", "B", "C"])

# æ»‘å—
value = st.slider("æ•°å€¼", 0, 100, 50)

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡ä»¶")
if uploaded_file:
    content = uploaded_file.read()  # è¯»å–æ–‡ä»¶å†…å®¹
```

### æ˜¾ç¤ºç»„ä»¶
```python
# æ ‡é¢˜å’Œæ–‡æœ¬
st.title("å¤§æ ‡é¢˜")
st.header("ä¸­æ ‡é¢˜")
st.subheader("å°æ ‡é¢˜")
st.write("æ™®é€šæ–‡æœ¬")
st.markdown("# ç”¨ Markdown æ ¼å¼")

# æç¤ºæ¡†
st.success("âœ… æˆåŠŸ")
st.error("âŒ é”™è¯¯")
st.warning("âš ï¸ è­¦å‘Š")
st.info("â„¹ï¸ ä¿¡æ¯")

# ä»£ç æ˜¾ç¤º
st.code("""
def hello():
    print("world")
""", language="python")

# è¡¨æ ¼
st.dataframe(dataframe_object)

# å›¾è¡¨ï¼ˆå¦‚æœè£…äº† plotlyï¼‰
import plotly.express as px
fig = px.bar(data, x='name', y='value')
st.plotly_chart(fig)
```

### å¸ƒå±€ç»„ä»¶
```python
# å¤šåˆ—å¸ƒå±€
col1, col2, col3 = st.columns(3)
with col1:
    st.write("ç¬¬ä¸€åˆ—")
with col2:
    st.write("ç¬¬äºŒåˆ—")

# ä¾§è¾¹æ 
with st.sidebar:
    st.write("è¿™æ˜¯ä¾§è¾¹æ ")

# æ ‡ç­¾é¡µï¼ˆStreamlit 1.26+ï¼‰
tab1, tab2 = st.tabs(["æ ‡ç­¾ 1", "æ ‡ç­¾ 2"])
with tab1:
    st.write("å†…å®¹ 1")
with tab2:
    st.write("å†…å®¹ 2")

# å®¹å™¨ï¼ˆç»„ç»‡å†…å®¹ï¼‰
with st.container():
    st.write("è¿™äº›å†…å®¹ä¼šç»„ç»‡åœ¨ä¸€èµ·")
```

### äº¤äº’ç»„ä»¶
```python
# æŒ‰é’®
if st.button("ç‚¹å‡»æˆ‘"):
    st.write("ä½ ç‚¹å‡»äº†ï¼")

# å¤é€‰æ¡†
if st.checkbox("åŒæ„æ¡æ¬¾"):
    st.write("è°¢è°¢åŒæ„ï¼")

# å•é€‰
choice = st.radio("é€‰æ‹©ä¸€ä¸ª", ["A", "B", "C"])

# åŠ è½½çŠ¶æ€ï¼ˆè¿›åº¦æ¡ï¼‰
with st.spinner("åŠ è½½ä¸­..."):
    time.sleep(3)

# è¿›åº¦æ¡
progress_bar = st.progress(0)
for i in range(100):
    progress_bar.progress(i + 1)

# ä¸‹è½½æŒ‰é’®
st.download_button(
    label="ä¸‹è½½æ•°æ®",
    data="file content",
    file_name="data.txt"
)
```

### Session Stateï¼ˆè®°ä½çŠ¶æ€ï¼‰
```python
# åˆå§‹åŒ–
if "counter" not in st.session_state:
    st.session_state.counter = 0

# ä½¿ç”¨
if st.button("å¢åŠ "):
    st.session_state.counter += 1

st.write(f"è®¡æ•°ï¼š{st.session_state.counter}")

# è¿™æ ·å³ä½¿ç”¨æˆ·äº¤äº’ï¼Œæ•°æ®ä¹Ÿä¸ä¼šä¸¢å¤±ï¼
```

---

## ğŸ’¡ å®æˆ˜æ¨¡å¼ï¼šRAG + Streamlit

**åœºæ™¯**ï¼šç”¨æˆ·ä¸Šä¼ æ–‡æ¡£ï¼Œæé—®æ–‡æ¡£å†…å®¹

**æ–‡ä»¶**: `rag_demo.py`

```python
import streamlit as st
import os
from dotenv import load_dotenv
from openai import OpenAI
import json

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

st.set_page_config(page_title="æ–‡æ¡£ RAG Demo", layout="wide")

st.title("ğŸ“„ æ–‡æ¡£é—®ç­”ç³»ç»Ÿ")

# ============ ä¾§è¾¹æ ï¼šç®¡ç†æ–‡æ¡£ ============
with st.sidebar:
    st.header("ğŸ“š æ–‡æ¡£ç®¡ç†")
    
    # åˆå§‹åŒ–å­˜å‚¨
    if "documents" not in st.session_state:
        st.session_state.documents = {}
    
    # ä¸Šä¼ æ–°æ–‡æ¡£
    uploaded_file = st.file_uploader("ä¸Šä¼  .txt æˆ– .md æ–‡æ¡£")
    if uploaded_file:
        content = uploaded_file.read().decode('utf-8')
        doc_name = uploaded_file.name
        st.session_state.documents[doc_name] = content
        st.success(f"âœ… å·²æ·»åŠ ï¼š{doc_name}")
    
    st.markdown("---")
    st.subheader("å·²åŠ è½½çš„æ–‡æ¡£")
    for doc_name in st.session_state.documents:
        st.write(f"ğŸ“„ {doc_name}")

# ============ ä¸»ç•Œé¢ï¼šæé—® ============
if st.session_state.documents:
    
    # é€‰æ‹©è¦æŸ¥è¯¢çš„æ–‡æ¡£
    selected_doc = st.selectbox(
        "é€‰æ‹©è¦æŸ¥è¯¢çš„æ–‡æ¡£",
        list(st.session_state.documents.keys())
    )
    
    # ç”¨æˆ·é—®é¢˜
    question = st.text_input("é—®ä½ çš„é—®é¢˜ï¼š")
    
    if question:
        # æ„é€  RAG æç¤ºè¯
        doc_content = st.session_state.documents[selected_doc]
        
        rag_prompt = f"""æ ¹æ®ä¸‹é¢çš„æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯´"æ–‡æ¡£ä¸­æ‰¾ä¸åˆ°ç›¸å…³ä¿¡æ¯"ã€‚

ã€æ–‡æ¡£å†…å®¹ã€‘
{doc_content}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{question}

ã€ä½ çš„å›ç­”ã€‘
"""
        
        with st.spinner("ğŸ”„ åˆ†æä¸­..."):
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£åˆ†æåŠ©æ‰‹ã€‚åŸºäºæä¾›çš„æ–‡æ¡£å‡†ç¡®å›ç­”é—®é¢˜ã€‚"},
                        {"role": "user", "content": rag_prompt}
                    ],
                    temperature=0.3  # é™ä½æ¸©åº¦ï¼Œæ›´ç¨³å®š
                )
                
                answer = response.choices[0].message.content
                
                st.success("âœ… å›ç­”å®Œæˆ")
                st.markdown("### ç­”æ¡ˆ")
                st.write(answer)
                
            except Exception as e:
                st.error(f"é”™è¯¯ï¼š{str(e)}")
else:
    st.warning("âš ï¸ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ æ–‡æ¡£")

st.caption("è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„ RAG demoï¼Œç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨å‘é‡æ•°æ®åº“")
```

**è¿è¡Œ**ï¼š
```bash
streamlit run rag_demo.py
```

**ä¸Šä¼ æµ‹è¯•æ–‡ä»¶**ï¼š
åˆ›å»º `test_doc.txt`ï¼š
```
æˆ‘ä»¬å…¬å¸æ˜¯ä¸€ä¸ª AI åˆ›ä¸šå…¬å¸ã€‚
CEO æ˜¯ Aliceï¼Œæˆç«‹äº 2024 å¹´ã€‚
ä¸»è¦äº§å“æ˜¯æ–‡æ¡£åˆ†æå¹³å°ã€‚
```

ç„¶åä¸Šä¼ ï¼Œæé—®ï¼š"CEO å«ä»€ä¹ˆåå­—ï¼Ÿ" â†’ åº”è¯¥å›ç­” "Alice"

---

## ğŸ¨ æ›´é«˜çº§çš„ Streamlit æŠ€å·§

### 1. è‡ªå®šä¹‰ä¸»é¢˜
```python
# streamlit_config.yaml (åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ .streamlit/ æ–‡ä»¶å¤¹ä¸­åˆ›å»º)
[theme]
primaryColor = "#FF6B6B"
backgroundColor = "#FFFFFF"
secondaryBackgroundColor = "#F0F2F6"
textColor = "#262730"
font = "sans serif"
```

### 2. éšè— Streamlit èœå•ï¼ˆç”Ÿäº§çº§ï¼‰
```python
st.set_page_config(initial_sidebar_state="collapsed")

hide_streamlit_style = """
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)
```

### 3. ä½¿ç”¨ Columns åšé«˜çº§å¸ƒå±€
```python
# å“åº”å¼å¸ƒå±€
st.title("é”€å”®ä»ªè¡¨æ¿")

col1, col2, col3 = st.columns([2, 1, 1])  # 2:1:1 çš„å®½åº¦æ¯”ä¾‹

with col1:
    st.metric("æ€»æ”¶å…¥", "$100K", "+5%")
with col2:
    st.metric("æ–°å®¢æˆ·", "23", "+3")
with col3:
    st.metric("æ»¡æ„åº¦", "92%", "-1%")
```

### 4. ç¼“å­˜ä¼˜åŒ–ï¼ˆåŠ å¿«é€Ÿåº¦ï¼‰
```python
# å¦‚æœæ•°æ®åŠ è½½æ…¢ï¼Œç”¨ cache è£…é¥°å™¨
@st.cache_data  # ç¼“å­˜æ•°æ®ï¼ˆä¸ä¼šå˜çš„æ•°æ®ï¼‰
def load_large_dataset():
    import pandas as pd
    return pd.read_csv("big_file.csv")

@st.cache_resource  # ç¼“å­˜èµ„æºï¼ˆå¦‚ LLM å®¢æˆ·ç«¯ï¼‰
def get_client():
    from openai import OpenAI
    return OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ç¬¬ä¸€æ¬¡è°ƒç”¨ä¼šå¾ˆæ…¢ï¼Œä¹‹åå°±å¿«äº†
df = load_large_dataset()
client = get_client()
```

---

## ğŸš€ Chainlit vs Streamlitï¼šé€‰æ‹©æŒ‡å—

| ç‰¹æ€§ | Streamlit | Chainlit |
|------|-----------|---------|
| å­¦ä¹ æ›²çº¿ | è¶…çº§ç®€å• âœ… | ä¸­ç­‰ |
| èŠå¤© UI | éœ€è¦è‡ªå·±å†™ | å†…ç½® âœ… |
| éƒ¨ç½²é€Ÿåº¦ | å¿« | å¿« |
| ç”Ÿäº§å°±ç»ª | å¯ä»¥ | æ›´ä¸“ä¸š âœ… |
| è‡ªå®šä¹‰ç¨‹åº¦ | é«˜ | ä¸­ç­‰ |

**å»ºè®®**ï¼š
- å¿«é€Ÿ Demo â†’ **Streamlit**ï¼ˆ2 å°æ—¶å†…ï¼‰
- æ­£å¼èŠå¤©äº§å“ â†’ **Chainlit**ï¼ˆé¢å¤– 1 å°æ—¶å­¦ä¹ ï¼‰
- å¤æ‚ç•Œé¢ â†’ **Streamlit**ï¼ˆè‡ªç”±åº¦æ›´é«˜ï¼‰

---

## ğŸ“¦ Chainlit å¿«é€Ÿç¤ºä¾‹

**å®‰è£…**ï¼š
```bash
pip install chainlit
```

**æœ€å°ç¤ºä¾‹** - `app.py`ï¼š
```python
from chainlit.input_widgets import Select
import chainlit as cl
from openai import AsyncOpenAI

client = AsyncOpenAI()

@cl.on_message
async def main(message: cl.Message):
    response = await client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": message.content}],
        stream=True,
    )
    
    msg = cl.Message(content="")
    async for chunk in response:
        if chunk.choices[0].delta.content:
            await msg.stream_token(chunk.choices[0].delta.content)
    
    await msg.send()
```

**è¿è¡Œ**ï¼š
```bash
chainlit run app.py
```

**ç‰¹ç‚¹**ï¼š
- è‡ªåŠ¨å¤„ç†èŠå¤©å†å² âœ…
- æ›´ä¼˜é›…çš„æµå¼è¾“å‡º âœ…
- æ›´ä¸“ä¸šçš„å¤–è§‚ âœ…

---

## ğŸ¯ å¸¸è§é—®é¢˜

### Q1: Streamlit å¦‚ä½•ä¿å­˜ç”¨æˆ·æ•°æ®ï¼Ÿ
A: ä½¿ç”¨ `st.session_state` ä¿å­˜å½“å‰ä¼šè¯æ•°æ®ã€‚å¦‚æœéœ€è¦æŒä¹…åŒ–ï¼ˆç”¨æˆ·åˆ·æ–°åè¿˜æœ‰ï¼‰ï¼Œéœ€è¦ï¼š
```python
import json

# ä¿å­˜åˆ°æ–‡ä»¶
def save_data(data):
    with open("data.json", "w") as f:
        json.dump(data, f)

# åŠ è½½
def load_data():
    if os.path.exists("data.json"):
        with open("data.json") as f:
            return json.load(f)
    return {}
```

### Q2: å¦‚ä½•å¤„ç†å¤§æ–‡ä»¶ä¸Šä¼ ï¼Ÿ
A:
```python
uploaded_file = st.file_uploader("ä¸Šä¼  CSV")
if uploaded_file is not None:
    # å¤„ç†å¤§æ–‡ä»¶ï¼Œåˆ†å—è¯»å–
    for chunk in pd.read_csv(uploaded_file, chunksize=1000):
        # å¤„ç†æ¯ä¸ª chunk
        pass
```

### Q3: å¦‚ä½•åœ¨ Streamlit ä¸­æ˜¾ç¤ºé•¿æ–‡æœ¬è€Œä¸å¡é¡¿ï¼Ÿ
A:
```python
# ä¸å¥½çš„æ–¹å¼ï¼ˆä¼šå¡ï¼‰
st.write(very_long_text)

# å¥½çš„æ–¹å¼
st.text_area("å†…å®¹", value=very_long_text, disabled=True)

# æˆ–è€…ç”¨ markdown çš„ä»£ç å—
st.markdown(f"```\n{very_long_text}\n```")
```

### Q4: å¦‚ä½•éƒ¨ç½² Streamlit åº”ç”¨ï¼Ÿ
A:
1. **æœ€å¿«æ–¹å¼**ï¼ˆå…è´¹ï¼‰ï¼šStreamlit Cloud
   ```bash
   # æ¨é€åˆ° GitHub
   git push origin main
   
   # åœ¨ https://share.streamlit.io è¿æ¥ä½ çš„ GitHub repo
   # Streamlit ä¼šè‡ªåŠ¨éƒ¨ç½²ï¼
   ```

2. **ä¸“ä¸šæ–¹å¼**ï¼šè‡ªå·±çš„æœåŠ¡å™¨
   ```bash
   # åœ¨æœåŠ¡å™¨ä¸Š
   streamlit run app.py --server.port 80 --server.address 0.0.0.0
   ```

---

## âœ… Day 2-3 ä»»åŠ¡æ¸…å•

- [ ] å®‰è£… Streamlitï¼ˆ`pip install streamlit`ï¼‰
- [ ] è¿è¡Œ `hello_streamlit.py` ç¤ºä¾‹
- [ ] ç†è§£ `st.session_state` çš„å·¥ä½œåŸç†
- [ ] ä¿®æ”¹ `faq_bot.py` ä¸­çš„ System Prompt
- [ ] æˆåŠŸéƒ¨ç½²ä¸€ä¸ªç®€å•çš„ Streamlit åº”ç”¨
- [ ] ï¼ˆå¯é€‰ï¼‰å°è¯• Chainlit ç¤ºä¾‹

**ç›®æ ‡**ï¼šåˆ° Day 3 ç»“æŸï¼Œä½ èƒ½åœ¨ 30 åˆ†é’Ÿå†…ç”¨ Streamlit å†™å‡ºä¸€ä¸ªèƒ½æ¼”ç¤ºçš„ Demoã€‚

---

## ğŸ“š æ¨èèµ„æº

- **Streamlit å®˜æ–¹æ–‡æ¡£**ï¼šhttps://docs.streamlit.io
- **Chainlit å®˜æ–¹æ–‡æ¡£**ï¼šhttps://docs.chainlit.io
- **Streamlit Gallery**ï¼šhttps://streamlit.io/galleryï¼ˆçœ‹åˆ«äººæ€ä¹ˆå†™çš„ï¼‰

---

**å®Œæˆæœ¬ç« åï¼Œä½ å·²ç»æŒæ¡äº† FDE æœ€å¸¸ç”¨çš„å·¥å…·ï¼** ğŸ‰

ä¸‹ä¸€æ­¥ï¼šç”¨ Streamlit + API å®Œæˆ Project_01_FAQ_Bot

æœ€åæ›´æ–°: 2025-12-22
